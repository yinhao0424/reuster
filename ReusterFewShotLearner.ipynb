{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReusterFewShotLearner.ipynb",
      "provenance": [],
      "mount_file_id": "1V6pvVcsoLQJKkS5V4InbEKWRQDh9xX7J",
      "authorship_tag": "ABX9TyMoncveHPzDCwbvr7Ai9QpM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinhao0424/reuster/blob/master/ReusterFewShotLearner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cwKBtxgxHRX"
      },
      "source": [
        "Reference:\n",
        "- [Sentence-BERT](https://www.aclweb.org/anthology/D19-1410.pdf)\n",
        "- [Sentence Embeddings using Siamese BERT-Networks](https://github.com/aneesha/SiameseBERT-Notebook/blob/master/SiameseBERT_SemanticSearch.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw3viDMDjJyZ",
        "outputId": "97ab6726-3ae6-498f-f9d6-3780bd55eadb"
      },
      "source": [
        "# a specific version of transformaer has been used \n",
        "! pip install -q transformers==3.0.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 34.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 57.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 53.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt2fu-WpjAPH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36SizijJvWkJ"
      },
      "source": [
        "# Sections of config\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3aClwrmljPgj",
        "outputId": "76b1a287-55ad-40da-83fe-a6fa47248874"
      },
      "source": [
        "reuster_train = pd.read_csv('/content/drive/MyDrive/data/reuters/reuster_fewshot_train.csv')\n",
        "reuster_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>topics</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4016</td>\n",
              "      <td>iron-steel</td>\n",
              "      <td>usx &lt;x&gt; proved oil, gas reserves fall in 1986u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4022</td>\n",
              "      <td>carcass</td>\n",
              "      <td>argentine meat exports higher in jan/feb 1987a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4022</td>\n",
              "      <td>livestock</td>\n",
              "      <td>argentine meat exports higher in jan/feb 1987a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4035</td>\n",
              "      <td>veg-oil</td>\n",
              "      <td>british minister criticises proposed ec oils t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4040</td>\n",
              "      <td>oilseed</td>\n",
              "      <td>china's rapeseed crop damaged by stormsthe yie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id      topics                                              texts\n",
              "0  4016  iron-steel  usx <x> proved oil, gas reserves fall in 1986u...\n",
              "1  4022     carcass  argentine meat exports higher in jan/feb 1987a...\n",
              "2  4022   livestock  argentine meat exports higher in jan/feb 1987a...\n",
              "3  4035     veg-oil  british minister criticises proposed ec oils t...\n",
              "4  4040     oilseed  china's rapeseed crop damaged by stormsthe yie..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGkaOQbnjPuF",
        "outputId": "1497cc2b-ad40-433d-fd26-c19fe3356e02"
      },
      "source": [
        "reuster_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1143, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrAnslsElya4"
      },
      "source": [
        "# #iron-steel\n",
        "# reuster_train.topics[0]\n",
        "# topics = reuster_train.topics\n",
        "# candi = topics[topics!='iron-steel'].index\n",
        "# idx = np.random.choice(candi)\n",
        "\n",
        "# print(topics[idx])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P09PmVIRuPlh"
      },
      "source": [
        "class FewShotDataset(Dataset):\n",
        "    \"\"\"\n",
        "        Input: a dataframe\n",
        "        output: anchor, positive and negative\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.texts\n",
        "        self.topics = self.data.topics\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        anchor = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {'anchor':{\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)},\n",
        "        'positive': self.get_positive(index),\n",
        "        'negative': self.get_negative(index)\n",
        "        }\n",
        "\n",
        "    def get_positive(self, index):\n",
        "         # the topic\n",
        "        topic = self.topics[index]\n",
        "\n",
        "        # select positive data which have the same topic with the anchor\n",
        "        candidates = self.topics[self.topics==topic].index\n",
        "        p_idx = index\n",
        "        while p_idx == index:\n",
        "          p_idx = np.random.choice(candidates)\n",
        "        \n",
        "        text = str(self.text[p_idx])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        positive = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ids = positive['input_ids']\n",
        "        mask = positive['attention_mask']\n",
        "        token_type_ids = positive[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)}\n",
        "\n",
        "    def get_negative(self, index):\n",
        "         # the topic\n",
        "        topic = self.topics[index]\n",
        "\n",
        "        # select positive data which have the same topic with the anchor\n",
        "        candidates = self.topics[self.topics!=topic].index\n",
        "        n_idx = index\n",
        "        n_idx = np.random.choice(candidates)\n",
        "        \n",
        "        text = str(self.text[n_idx])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        negative = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = negative['input_ids']\n",
        "        mask = negative['attention_mask']\n",
        "        token_type_ids = negative[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqQNXOPslqo6",
        "outputId": "4ffb2cd2-642d-49d7-e8f8-66d2de3c7315"
      },
      "source": [
        "print(\"TRAIN Dataset: {}\".format(reuster_train.shape))\n",
        "# print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = FewShotDataset(reuster_train, tokenizer, MAX_LEN)\n",
        "# testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN Dataset: (1143, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKdMcmgovsnK"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "# testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdrZU8QuvvSl",
        "outputId": "dbc19497-9e5d-421a-9674-21a5b5f9ed8a"
      },
      "source": [
        "print(\"The len of training loader is {}.\".format(len(training_loader)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The len of training loader is 286.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky2cZcupwJY2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8c5Z5-qwJ8U"
      },
      "source": [
        "## Create the Neural Network for Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-9OVcyyv4KQ"
      },
      "source": [
        "class DistilBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(768, 9)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.Tanh()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = DistilBERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}